# Papers Accepted by AAAI 2021
- [Papers Accepted by AAAI 2021](#papers-accepted-by-aaai-2021)
  - [一、命名实体识别](#一命名实体识别)
    - [1. Multi-modal Graph Fusion for Named Entity Recognition with Targeted VisualGuidance**](#1-multi-modal-graph-fusion-for-named-entity-recognition-with-targeted-visualguidance)
    - [2. CrossNER: Evaluating Cross-Domain Named Entity Recognition](#2-crossner-evaluating-cross-domain-named-entity-recognition)
    - [3. Nested Named Entity Recognition with Partially-Observed TreeCRFs**](#3-nested-named-entity-recognition-with-partially-observed-treecrfs)
    - [4.Continual Learning for Named Entity Recognition](#4continual-learning-for-named-entity-recognition)
    - [5. Knowledge-Aware Named Entity Recognition with Alleviating Heterogeneity](#5-knowledge-aware-named-entity-recognition-with-alleviating-heterogeneity)
    - [6.Denoising Distantly Supervised Named Entity Recognition via a Hypergeometric Probabilistic Model](#6denoising-distantly-supervised-named-entity-recognition-via-a-hypergeometric-probabilistic-model)
    - [7. MTAAL: Multi-Task Adversarial Active Learning for Medical Named Entity Recognition and Normalization](#7-mtaal-multi-task-adversarial-active-learning-for-medical-named-entity-recognition-and-normalization)
  - [二、关系抽取](#二关系抽取)
    - [1. FL-MSRE: A Few-Shot Learning Based Approach to Multimodal Social Relation Extraction](#1-fl-msre-a-few-shot-learning-based-approach-to-multimodal-social-relation-extraction)
    - [2. Multi-View Inference for Relation Extraction with Uncertain Knowledge](#2-multi-view-inference-for-relation-extraction-with-uncertain-knowledge)
    - [3. GDPNet: Refining Latent Multi-View Graph for Relation Extraction](#3-gdpnet-refining-latent-multi-view-graph-for-relation-extraction)
    - [4. Progressive Multi-Task Learning with Controlled information Flow for Joint Entity and Relation Extraction](#4-progressive-multi-task-learning-with-controlled-information-flow-for-joint-entity-and-relation-extraction)
    - [5. Curriculum-Meta Learning for Order-Robust Continual Relation Extraction](#5-curriculum-meta-learning-for-order-robust-continual-relation-extraction)
    - [6. Document-Level Relation Extraction with Reconstruction](#6-document-level-relation-extraction-with-reconstruction)
    - [7. Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling](#7-document-level-relation-extraction-with-adaptive-thresholding-and-localized-context-pooling)
    - [8. Entity Structure Within and Throughout: Modeling Mention Dependencies for Document Level Relation Extraction](#8-entity-structure-within-and-throughout-modeling-mention-dependencies-for-document-level-relation-extraction)
    - [9. Empower Distantly Supervised Relation Extraction with Collaborative Adversarial Training](#9-empower-distantly-supervised-relation-extraction-with-collaborative-adversarial-training)
    - [10. Clinical Temporal Relation Extraction with Probabilistic Soft Logic Regularization and Global Inference](#10-clinical-temporal-relation-extraction-with-probabilistic-soft-logic-regularization-and-global-inference)
    - [11. A Unified Multi-Task Learning Framework for Joint Extraction of Entities and Relations](#11-a-unified-multi-task-learning-framework-for-joint-extraction-of-entities-and-relations)
  - [三、事件抽取](#三事件抽取)
    - [1. GATE: Graph Attention Transformer Encoder for Cross-Lingual Relation and Event Extraction](#1-gate-graph-attention-transformer-encoder-for-cross-lingual-relation-and-event-extraction)
    - [2. What the Role Is vs. What Plays the Role: Semi-Supervised Event Argument Extraction via Dual Question Answering](#2-what-the-role-is-vs-what-plays-the-role-semi-supervised-event-argument-extraction-via-dual-question-answering)
    - [3. Span-Based Event Coreference Resolution](#3-span-based-event-coreference-resolution)
## 一、命名实体识别
### 1. Multi-modal Graph Fusion for Named Entity Recognition with Targeted VisualGuidance**

Dong Zhang1, Suzhong Wei2, Shoushan Li1∗, Hanqian Wu2, Qiaoming Zhu1, Guodong Zhou1,

1 School of Computer Science and Technology, Soochow University, China

2 School of Computer Science and Engineering, Southeast University, China

**Abstract**

Multi-modal named entity recognition(MNER) aims to discover named entities in free text and classify them into predefined types with images. However, dominant MNER models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have the potential to refine multi-modal representation learning. To deal with this issue, we propose a unified multi-modal graph fusion(UMGF) approach for MNER. Specifically, we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units (words and visual objects). Then, we stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations. Finally, we achieve an attention-based multi-modal representation for each word and perform entity labeling with a CRF decoder. Experimentation on the two benchmark datasets demonstrates the superiority of our MNER model.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-2753.ZhangD.pdf)

### 2. CrossNER: Evaluating Cross-Domain Named Entity Recognition

Zihan Liu, Yan Xu, Tiezheng Yu, Wenliang Dai, Ziwei Ji, Samuel Cahyawijaya, Andrea Madotto, Pascale Fung

Center for Artificial Intelligence Research(CAiRE), The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong

**Abstract**

Cross-domain named entity recognition (NER) models are able to cope with the scarcity issue of NER samples in target domains. However, most of the existing NER benchmarks lack domain-specialized entity types or do not focus on a certain domain, leading to a less effective cross-domain evaluation. To address these obstacles, we introduce a cross-domain NER dataset (CrossNER), a fully-labeled collection of NER data spanning over five diverse domains with specialized entity categories for different domains. Additionally, we also provide a domain-related corpus since using it to continue pre-training language models (domain-adaptive pre-training) is effective for the domain adaptation. We then conduct comprehensive experiments to explore the effectiveness of leveraging different levels of the domain corpus and pre-training strategies to do domain-adaptive pre-training for the cross-domain task. Results show that focusing on the fractional corpus containing domain-specialized entities and utilizing a more challenging pre-training strategy in domain-adaptive pre-training are beneficial for the NER domain adaptation, and our proposed method can consistently outperform existing cross-domain NER baselines. Nevertheless, experiments also illustrate the challenge of this cross-domain NER task. We hope that our dataset and baselines will catalyze research in the NER domain adaptation area. The code and data are available at [this https URL](https://github.com/zliucr/CrossNER).

[[paper]](https://arxiv.org/abs/2012.04373) last revised 13 Dec 2020

### 3. Nested Named Entity Recognition with Partially-Observed TreeCRFs**

Yao Fu1, Chuanqi Tan2, Mosha Chen2, Songfang Huang2, Fei Huang2

1 University of Edinburgh 

2 Alibaba Group

**Abstract**

Named entity recognition (NER) is a well-studied task in natural language processing. However, the widely-used sequence labeling framework is difficult to detect entities with nested structures. In this work, we view nested NER as constituency parsing with partially-observed trees and model it with partially-observed TreeCRFs. Specifically, we view all labeled entity spans as observed nodes in a constituency tree, and other spans as latent nodes. With the TreeCRF we achieve a uniform way to jointly model the observed and the latent nodes. To compute the probability of partial trees with partial marginalization, we propose a variant of the Inside algorithm, the \textsc{Masked Inside} algorithm, that supports different inference operations for different nodes (evaluation for the observed, marginalization for the latent, and rejection for nodes incompatible with the observed) with efficient parallelized implementation, thus significantly speeding up training and inference. Experiments show that our approach achieves the state-of-the-art (SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable performance to SOTA models on the GENIA dataset. Our approach is implemented at: [\url{this https URL}](https://github.com/FranxYao/Partially-Observed-TreeCRFs).

[[paper]](https://arxiv.org/abs/2012.08478)

### 4.Continual Learning for Named Entity Recognition

Natawut Monaikul∗1, Giuseppe Castellucci2, Simone Filice2, Oleg Rokhlenko2

1 University of Illinois at Chicago, Chicago, IL, USA

2 Amazon, Seattle, WA, USA

**Abstract**

Named Entity Recognition (NER) is a vital task in various NLP applications. However, in many real-world scenarios (e.g., voice-enabled assistants) new named entity types are frequently introduced, entailing re-training NER models to support these new entity types. Re-annotating the original training data for the new entity types could be costly or even impossible when storage limitations or security concerns restrict access to that data, and annotating a new dataset for all of the entities becomes impractical and error-prone as the number of types increases. To tackle this problem, we introduce a novel Continual Learning approach for NER, which requires new training material to be annotated only for the new entity types. To preserve the existing knowledge previously learned by the model, we exploit the Knowledge Distillation (KD) framework, where the existing NER model acts as the teacher for a new NER model (i.e., the student), which learns the new entity types by using the new training material and retains knowledge of old entities by imitating the teacher’s outputs on this new training set. Our experiments show that this approach allows the student model to “progressively” learn to identify new entity types without forgetting the previously learned ones. We also present a comparison with multiple strong baselines to demonstrate that our approach is superior for continually updating an NER model.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-7791.MonaikulN.pdf)

### 5. Knowledge-Aware Named Entity Recognition with Alleviating Heterogeneity

Binling Nie1*, Ruixue Ding2, Pengjun Xie2, Fei Huang2, Chen Qian3, Luo Si2

1 HangZhou Dianzi University 

2 Alibaba Group 3 Tsinghua University

**Abstract**

Named Entity Recognition (NER) is a fundamental and important research topic for many downstream NLP tasks, aiming at detecting and classifying named entities(NEs) mentioned in unstructured text into pre-defined categories. Learning from labeled data only is far from enough when it comes to domain-specific or temporally-evolving entities (e.g. medical terminologies or restaurant names). Luckily, open-source Knowledge Bases (KBs) (e.g. Wikidata and Freebase) contain NEs that are manually labeled with predefined types in different domains, which is potentially beneficial to identify entity boundaries and recognize entity types more accurately. However, the type system of a domain-specific NER task is typically independent of that of current KBs and thus exhibits heterogeneity issue inevitably, which makes matching between the original NER and KB types (e.g. Person in NER potentially matches President in KBs) less likely, or introduces unintended noises without considering domainspecific knowledge (e.g. Band in NER should be mapped to Out of Entity Types in the restaurant-related task). To better incorporate and denoise the abundant knowledge in KBs, we propose a new KB-aware NER framework (KaNa), which utilizes type-heterogeneous knowledge to improve NER. Specifically, for an entity mention along with a set of candidate entities that are linked from KBs, KaNa first uses a type projection mechanism that maps the mention type and entity types into a shared space to homogenize the heterogeneous entity types. Then, based on projected types, a noise detector filters out certain less-confident candidate entities in an unsupervised manner. Finally, the filtered mention-entity pairs are injected into a NER model as a graph to predict answers. The experimental results demonstrate KaNa’s state-of-the-art performance on five public benchmark datasets from different domains, outperforming strong baselines by 1.33 F1 points on average

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-9155.NieB.pdf)

### 6.Denoising Distantly Supervised Named Entity Recognition via a Hypergeometric Probabilistic Model

Wenkai Zhang1,3,*, Hongyu Lin1,*, Xianpei Han1,2,†, Le Sun1,2,†, Huidan Liu1,  Zhicheng Wei4, Nicholas Jing Yuan4

1 Chinese Information Processing Laboratory 

2 State Key Laboratory of Computer Science
, Institute of Software, Chinese Academy of Sciences, Beijing, China

3 University of Chinese Academy of Sciences, Beijing, China

4 Huawei Cloud&AI

**Abstract**

Denoising is the essential step for distant supervision based named entity recognition. Previous denoising methods are mostly based on instance-level confidence statistics, which ignore the variety of the underlying noise distribution on different datasets and entity types. This makes them difficult to be adapted to high noise rate settings. In this paper, we propose Hypergeometric Learning (HGL), a denoising algorithm for distantly supervised NER that takes both noise distribution and instance-level confidence into consideration. Specifically, during neural network training, we naturally model the noise samples in each batch following a hypergeometric distribution parameterized by the noise-rate. Then each instance in the batch is regarded as either correct or noisy one according to its label confidence derived from previous training step, as well as the noise distribution in this sampled batch. Experiments show that HGL can effectively denoise the weakly-labeled data retrieved from distant supervision, and therefore results in significant improvements on the trained models.

[[paper]](https://arxiv.org/abs/2106.09234)

### 7. MTAAL: Multi-Task Adversarial Active Learning for Medical Named Entity Recognition and Normalization

Baohang Zhou1,3, Xiangrui Cai2,3, Ying Zhang1,3∗, Wenya Guo1,3, Xiaojie Yuan1,3,

1 College of Computer Science, Nankai University, Tianjin 300350, China

2 College of Cyber Science, Nankai University, Tianjin 300350, China

3 Tianjin Key Laboratory of Network and Data Security Technology, Tianjin 300350, China

**Abstract**

Automated medical named entity recognition and normalization are fundamental for constructing knowledge graphs and building QA systems. When it comes to medical text, the annotation demands a foundation of expertise and professionalism. Existing methods utilize active learning to reduce costs in corpus annotation, as well as the multi-task learning strategy to model the correlations between different tasks. However, existing models do not take task-specific features for different tasks and diversity of query samples into account. To address these limitations, this paper proposes a multi-task adversarial active learning model for medical named entity recognition and normalization. In our model, the adversarial learning keeps the effectiveness of multi-task learning module and active learning module. The task discriminator eliminates the influence of irregular task-specific features. And the diversity discriminator exploits the heterogeneity between samples to meet the diversity constraint. The empirical results on two medical benchmarks demonstrate the effectiveness of our model against the existing methods.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-10063.ZhouB.pdf)

## 二、关系抽取
### 1. FL-MSRE: A Few-Shot Learning Based Approach to Multimodal Social Relation Extraction

Hai Wan1, Manrong Zhang1, Jianfeng Du2∗， Ziling Huang1， Yufei Yang1， Jeff Z. Pan3

1 School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou 510006, P.R.China

2 Guangzhou Key Laboratory of Multilingual Intelligent Processing, Guangdong University of Foreign Studies, Guangzhou 510006, P.R.China

3 School of Informatics, The University of Edinburgh, Edinburgh, UK

**Abstract**

Social relation extraction (SRE for short), which aims to infer the social relation between two people in daily life, has been demonstrated to be of great value in reality. Existing methods for SRE consider extracting social relation only from uni-modal information such as text or image, and ignore the high coupling in multimodal information. Moreover, previous studies overlook the serious unbalance distribution on social relations. To address these issues, this paper proposes FL-MSRE, a few-shot learning based approach to extracting social relations from both texts and face images. As far as we know, this is the first attempt to leverage both text and image for SRE. Considering the lack of multimodal social relation datasets, this paper presents three multimodal datasets annotated from four classical masterpieces and corresponding TV series. Inspired by the success of BERT, we propose a strong BERT based baseline to extract social relation from text only. FL-MSRE is empirically shown to outperform the baseline significantly. This demonstrates that using face images benefits text-based SRE. Further experiments also demonstrate that using two face images from different scenes achieves similar performance as from the same scene. This means that FL-MSRE is suitable for a wide range of SRE applications where face images about different people can only be collected from different scenes.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-2215.WanH.pdf)

### 2. Multi-View Inference for Relation Extraction with Uncertain Knowledge

Bo Li1,2, Wei Ye1*, Canming Huang3, Shikun Zhang1

1 National Engineering Research Center for Software Engineering, Peking University

2 School of Software and Microelectronics, Peking University

3 Beijing University of Posts and Telecommunications

### Abstract

Knowledge graphs (KGs) are widely used to facilitate relation extraction (RE) tasks. While most previous RE methods focus on leveraging deterministic KGs, uncertain KGs, which assign a confidence score for each relation instance, can provide prior probability distributions of relational facts as valuable external knowledge for RE models. This paper proposes to exploit uncertain knowledge to improve relation extraction. Specifically, we introduce ProBase, an uncertain KG that indicates to what extent a target entity belongs to a concept, into our RE architecture. We then design a novel multi-view inference framework to systematically integrate local context and global knowledge across three views: mention-, entity- and concept-view. The experimental results show that our model achieves competitive performances on both sentence- and document-level relation extraction, which verifies the effectiveness of introducing uncertain knowledge and the multi-view inference framework that we design.

[[paper]](https://arxiv.org/abs/2104.13579)

### 3. GDPNet: Refining Latent Multi-View Graph for Relation Extraction

Fuzhao Xue1, Aixin Sun1, Hao Zhang1,2, Eng Siong Chng1

1 School of Computer Science and Engineering, Nanyang Technological University, Singapore

2 Institute of High Performance Computing, A*STAR, Singapore

**Abstract**

Relation Extraction(RE) is to predict the relation type of two entities that are mentioned in a piece of text, e.g., a sentence or a dialogue. When the given text is long, it is challenging to identify indicative words for the relation prediction. Recent advances on RE task are from BERT-based sequence modeling and graph-based modeling of relationships among the tokens in the sequence. In this paper, we propose to construct a latent multi-view graph to capture various possible relationships among tokens. We then refine this graph to select important words for relation prediction. Finally, the representation of the refined graph and the BERT-based sequence representation are concatenated for relation extraction. Specifically, in our proposed GDPNet (Gaussian Dynamic Time Warping Pooling Net), we utilize Gaussian Graph Generator(GGG) to generate edges of the multi-view graph. The graph is then refined by Dynamic Time Warping Pooling (DTWPool). On DialogRE and TACRED, we show that GDPNet achieves the best performance on dialogue-level RE, and comparable performance with the state-of-the-arts on sentence-level RE.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-3290.XueF.pdf)

### 4. Progressive Multi-Task Learning with Controlled information Flow for Joint Entity and Relation Extraction

Kai Sun1,2, Richong Zhang,1,2∗, Samuel Mensah1,2, Yongyi Mao3, Xudong Liu1,,2

1 Beijing Advanced Institution for Big Data and Brain Computing, Beihang University, Beijing, China

2 SKLSDE, School of Computer Science and Engineering, Beihang University, Beijing, China

3 School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada

**Abstract**

Multitask learning has shown promising performance in learning multiple related tasks simultaneously, and variants of model architectures have been proposed, especially for supervised classification problems. One goal of multitask learning is to extract a good representation that sufficiently captures the relevant part of the input about the output for each learning task. To achieve this objective, in this paper we design a multitask learning architecture based on the observation that correlations exist between outputs of some related tasks (e.g. entity recognition and relation extraction tasks), and they reflect the relevant features that need to be extracted from the input. As outputs are unobserved, our proposed model exploits task predictions in lower layers of the neural model, also referred to as early predictions in this work. But we control the injection of early predictions to ensure that we extract good task-specific representations for classification. We refer to this model as a Progressive Multitask learning model with Explicit Interactions(PMEI). Extensive experiments on multiple benchmark datasets produce state-of-the-art results on the joint entity and relation extraction task.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-4619.SunK.pdf)

### 5. Curriculum-Meta Learning for Order-Robust Continual Relation Extraction

Tongtong Wu1∗, Xuekai Li1, Yuan-Fang Li2, Gholamreza Haffari2, Guilin Qi1†, Yujin Zhu3, Guoqiang Xu3

1 School of Computer Science and Engineering, Southeast University, Nanjing, China

2 Faculty of Information Technology, Monash University, Melbourne, Australia

3 Gamma Lab, Ping An OneConnect, Shanghai, China

**Abstract**

Continual relation extraction is an important task that focuses on extracting new facts incrementally from unstructured text. Given the sequential arrival order of the relations, this task is prone to two serious challenges, namely catastrophic forgetting and order-sensitivity. We propose a novel curriculum-meta learning method to tackle the above two challenges in continual relation extraction. We combine meta learning and curriculum learning to quickly adapt model parameters to a new task and to reduce interference of previously seen tasks on the current task. We design a novel relation representation learning method through the distribution of domain and range types of relations. Such representations are utilized to quantify the difficulty of tasks for the construction of curricula. Moreover, we also present novel difficulty-based metrics to quantitatively measure the extent of order-sensitivity of a given model, suggesting new ways to evaluate model robustness. Our comprehensive experiments on three benchmark datasets show that our proposed method outperforms the state-of-the-art techniques. The code is available at the anonymous GitHub repository https://github.com/wutong8023/AAAI-CML.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-4847.WuT.pdf)

### 6. Document-Level Relation Extraction with Reconstruction

Wang Xu1, Kehai Chen2, and Tiejun Zhao1

1 Harbin Institute of Technology, Harbin, China

2 National Institute of Information and Communications Technology (NICT), Kyoto, Japan

**Abstract**

In document-level relation extraction (DocRE), graph structure is generally used to encode relation information in the input document to classify the relation category between each entity pair, and has greatly advanced the DocRE task over the past several years. However, the learned graph representation universally models relation information between all entity pairs regardless of whether there are relationships between these entity pairs. Thus, those entity pairs without relationships disperse the attention of the encoder-classifier DocRE for ones with relationships, which may further hind the improvement of DocRE. To alleviate this issue, we propose a novel encoder-classifier-reconstructor model for DocRE. The reconstructor manages to reconstruct the ground-truth path dependencies from the graph representation, to ensure that the proposed DocRE model pays more attention to encode entity pairs with relationships in the training. Furthermore, the reconstructor is regarded as a relationship indicator to assist relation classification in the inference, which can further improve the performance of DocRE model. Experimental results on a large-scale DocRE dataset show that the proposed model can significantly improve the accuracy of relation extraction on a strong heterogeneous graph-based baseline. The code is publicly available at https://github.com/xwjim/DocRE-Rec.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-5035.XuW.pdf)

### 7. Document-Level Relation Extraction with Adaptive Thresholding and Localized Context Pooling

Wenxuan Zhou1*, Kevin Huang2, Tengyu Ma3†, Jing Huang2

1 Department of Computer Science, University of Southern California, Los Angeles, CA

2 JD AI Research, Mountain View, CA

3 Department of Computer Science, Stanford University, Stanford, CA

**Abstract**

Document-level relation extraction (RE) poses new challenges compared to its sentence-level counterpart. One document commonly contains multiple entity pairs, and one entity pair occurs multiple times in the document associated with multiple possible relations. In this paper, we propose two novel techniques, adaptive thresholding and localized context pooling, to solve the multi-label and multi-entity problems. The adaptive thresholding replaces the global threshold for multi-label classification in the prior work with a learnable entities-dependent threshold. The localized context pooling directly transfers attention from pre-trained language models to locate relevant context that is useful to decide the relation. We experiment on three document-level RE benchmark datasets: DocRED, a recently released large-scale RE dataset, and two datasets CDR and GDA in the biomedical domain. Our ATLOP (Adaptive Thresholding and Localized context Pooling) model achieves an F1 score of 63.4, and also significantly outperforms existing models on both CDR and GDA. We have released our code at https://github.com/wzhouad/ATLOP

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-8308.ZhouW.pdf)

### 8. Entity Structure Within and Throughout: Modeling Mention Dependencies for Document Level Relation Extraction

Benfeng Xu1*, Quan Wang2, Yajuan Lyu2, Yong Zhu2, Zhendong Mao1†

1 School of Information Science and Technology, University of Science and Technology of China, Hefei, China

2 Baidu Inc., Beijing, China

**Abstract**

Entities, as the essential elements in relation extraction tasks, exhibit certain structure. In this work, we formulate such structure as distinctive dependencies between mention pairs. We then propose SSAN, which incorporates these structural dependencies within the standard self-attention mechanism and throughout the overall encoding stage. Specifically, we design two alternative transformation modules inside each self-attention building block to produce attentive biases so as to adaptively regularize its attention flow. Our experiments demonstrate the usefulness of the proposed entity structure and the effectiveness of SSAN. It significantly outperforms competitive baselines, achieving new state-of-the-art results on three popular document-level relation extraction datasets. We further provide ablation and visualization to show how the entity structure guides the model for better relation extraction. Our code is publicly available.

[[paper]](https://arxiv.org/abs/2102.10249)

### 9. Empower Distantly Supervised Relation Extraction with Collaborative Adversarial Training

Tao Chen1, Haochen Shi1, Liyuan Liu2, Siliang Tang1*, Jian Shao1, Zhigang Chen3, Yueting Zhuang1

1 Zhejiang University 

2 University of Illinois at Urbana Champaign 

3 iFLYTEK Research

**Abstract**

With recent advances in distantly supervised (DS) relation extraction (RE), considerable attention is attracted to leverage multi-instance learning (MIL) to distill high-quality supervision from the noisy DS. Here, we go beyond label noise and identify the key bottleneck of DS-MIL to be its low data utilization: as high-quality supervision being refined by MIL, MIL abandons a large amount of training instances, which leads to a low data utilization and hinders model training from having abundant supervision. In this paper, we propose collaborative adversarial training to improve the data utilization, which coordinates virtual adversarial training (VAT) and adversarial training (AT) at different levels. Specifically, since VAT is label-free, we employ the instance-level VAT to recycle instances abandoned by MIL. Besides, we deploy AT at the bag-level to unleash the full potential of the high-quality supervision got by MIL. Our proposed method brings consistent improvements (∼ 5 absolute AUC score) to the previous state of the art, which verifies the importance of the data utilization issue and the effectiveness of our method.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-9721.ChenT.pdf)

### 10. Clinical Temporal Relation Extraction with Probabilistic Soft Logic Regularization and Global Inference

Yichao Zhou1, Yu Yan2, Rujun Han3, J. Harry Caufield2, Kai-Wei Chang1, Yizhou Sun1, Peipei Ping2, Wei Wang1

1 Department of Computer Science, University of California, Los Angeles.

2 Departments of Physiology, Medicine and Bioinformatics, University of California, Los Angeles.

3 Department of Computer Science, University of Southern California, Los Angeles.

**Abstract**

There has been a steady need in the medical community to precisely extract the temporal relations between clinical events. In particular, temporal information can facilitate a variety of downstream applications such as case report retrieval and medical question answering. However, existing methods either require expensive feature engineering or are incapable of modeling the global relational dependencies among the events. In this paper, we propose Clinical Temporal ReLation Exaction with Probabilistic Soft Logic Regularization and Global Inference (CTRL-PG), a novel method to tackle the problem at the document level. Extensive experiments on two benchmark datasets, I2B2-2012 and TB-Dense, demonstrate that CTRL-PG significantly outperforms baseline methods for temporal relation extraction.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-9740.ZhouY.pdf)

### 11. A Unified Multi-Task Learning Framework for Joint Extraction of Entities and Relations

Tianyang Zhao1, Zhao Yan2, Yunbo Cao2, Zhoujun Li1*

1 State Key Lab of Software Development Environment, Beihang University, Beijing, China

2 Tencent Cloud Xiaowei, Beijing, China

**Abstract**

Joint extraction of entities and relations focuses on detecting entity pairs and their relations simultaneously with a unified model. Based on the extraction order, previous works mainly solve this task through relation-last, relation-first and relation-middle manner. However, these methods still suffer from the template-dependency, non-entity detection and non-predefined relation prediction problem. To overcome these challenges, in this paper, we propose a unified multi-task learning framework to divide the task into three interacted sub-tasks. Specifically, we first introduce the type-attentional method for subject extraction to provide prior type information explicitly. Then, the subject-aware relation prediction is presented to select useful relations based on the combination of global and local semantics. Third, we propose a question generation based QA method for object extraction to obtain diverse queries automatically. Notably, our method detects subjects or objects without relying on NER models and thus it is capable of dealing with the non-entity scenario. Finally, three sub-tasks are integrated into a unified model through parameter sharing. Extensive experiments demonstrate that the proposed framework outperforms all the baseline methods on two benchmark datasets, and further achieve excellent performance for non-predefined relations.

[[paper]](https://ojs-aaai-ex4-oa-ex0-www-webvpn.webvpn2.hrbcu.edu.cn/index.php/AAAI/article/view/17707)

## 三、事件抽取
### 1. GATE: Graph Attention Transformer Encoder for Cross-Lingual Relation and Event Extraction

Wasi Uddin Ahmad, Nanyun Peng, Kai-Wei Chang

University of California, Los Angeles

**Abstract**

Recent progress in cross-lingual relation and event extraction use graph convolutional networks (GCNs) with universal dependency parses to learn language-agnostic sentence representations such that models trained on one language can be applied to other languages. However, GCNs struggle to model words with long-range dependencies or are not directly connected in the dependency tree. To address these challenges, we propose to utilize the self-attention mechanism where we explicitly fuse structural information to learn the dependencies between words with different syntactic distances. We introduce GATE, a Graph Attention Transformer Encoder, and test its cross-lingual transferability on relation and event extraction tasks. We perform experiments on the ACE05 dataset that includes three typologically different languages: English, Chinese, and Arabic. The evaluation results show that GATE outperforms three recently proposed methods by a large margin. Our detailed analysis reveals that due to the reliance on syntactic dependencies, GATE produces robust representations that facilitate transfer across languages

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-10207.AhmadW.pdf)

### 2. What the Role Is vs. What Plays the Role: Semi-Supervised Event Argument Extraction via Dual Question Answering

Yang Zhou1,2, Yubo Chen1,2, Jun Zhao1,2 Yin Wu3, Jiexin Xu3, Jinlong Li3

1 National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China

2 School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100049, China

3 AI Lab, China Merchant Bank, ShenZhen, 518057, China

**Abstract**

Event argument extraction is an essential task in event extraction, and become particularly challenging in the case of low-resource scenarios. We solve the issues in existing studies under low-resource situations from two sides. From the perspective of the model, the existing methods always suffer from the concern of insufficient parameter sharing and do not consider the semantics of roles, which is not conducive to dealing with sparse data. And from the perspective of the data, most existing methods focus on data generation and data augmentation. However, these methods rely heavily on external resources, which is more laborious to create than obtain unlabeled data. In this paper, we propose DualQA, a novel framework, which models the event argument extraction task as question answering to alleviate the problem of data sparseness and leverage the duality of event argument recognition which is to ask “What plays the role”, as well as event role recognition which is to ask “What the role is”, to mutually improve each other. Experimental results on two datasets prove the effectiveness of our approach, especially in extremely low-resource situations.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-2635.ZhouY.pdf)

### 3. Span-Based Event Coreference Resolution
Jing Lu, Vincent Ng

Human Language Technology Research Institute, University of Texas at Dallas， Richardson, TX 75083-0688

**Abstract**

Motivated by the recent successful application of span-based models to entity-based information extraction tasks, we investigate span-based models for event coreference resolution, focusing in particular on whether (1) the successes of span-based models of entity coreference can be extended to event coreference; (2) cross-task consistency constraints can be used to guide the learning of span-based event coreference models; and (3) automatically computed entity coreference information can benefit span-based event coreference resolution. Empirical results on two standard evaluation datasets provide affirmative answers to all three questions.

[[paper]](https://www.aaai.org/AAAI21Papers/AAAI-9086.LJ.pdf)
